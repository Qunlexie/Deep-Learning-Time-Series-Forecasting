# Abstract
This project aimed to build a time series regression model to predict future horizons using a provided dataset. The process involved conducting exploratory data analysis, feature engineering, and preprocessing. Both linear and non-linear time series forecasting models were explored, including Prophet (which has shown superior performance compared to other simple autoregressive models like SARIMA, ARIMA, and ARMA) and Neural Prophet (based on a feed-forward neural network architecture capable of capturing non-linear trend characteristics). Two variants of each of the Prophet and Neural Prophet model were developed, including a pre-tuned model and a hyperparameter-tuned model. The models used feature engineered regressor variables such as time-based variables (Day, Month, Year, and Quarter) and the provided exogenous variables (A1 and B1). Extensive cross-validation was conducted using the Mean Absolute Error, and the performance of the models (Baseline Prophet, Tuned Prophet Model, Pre-tuned Neural Prophet, and Hyperparameter-tuned Neural Prophet) were compared. Results showed that the Hyperparameter-tuned Neural Prophet model achieved the best performance. Additionally, the choice of MAE as the cross validation metric and the impact of the variable output length model was discussed, highlighting its flexibility advantage but added complexity compared to fixed horizon forecasts.

Keywords: Time Series Forecasting, Linear Model, Non-Linear Model, Prophet, Neural Prophet, Deep Learning

# Method 
![image.png](attachment:image.png)

# Summary 
This time series forecasting work evaluated two classes of models: the linear model (Prophet) and the non-linear model (Neural Prophet based on a deep learning architecture). Both tuned and pre-tuned variants of each model were examined, resulting in four models for forecasting the target variable over the next three horizons. The results indicated that the Tuned Neural Prophet model produced the lowest Mean Square Error, suggesting that it better captured the non-linear trends in the data.

# Future Work 
Despite the promising results obtained from this work, there are still opportunities for future work. One direction for future work would be to explore the use of other time series regression models like LSTM, GRU, and ConvLSTM, which are known for their ability to capture long-term dependencies and nonlinear patterns in time series data. Additionally, incorporating more exogenous variables or alternative feature engineering techniques, such as time-series cross-validation, may improve the model's performance. Finally, testing the models on larger and more diverse datasets with varying time-series characteristics could also provide more insights into the robustness and generalizability of the models developed in this work.